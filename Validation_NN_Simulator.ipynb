{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c6ca90-9e76-496a-b162-7990a2851649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Execution time: 0.31540346145629883 seconds\n",
      "Predicted data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "# Define the same model architecture\n",
    "# Define ResNetBlock1\n",
    "class ResNetBlock1(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResNetBlock1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.identity_downsample = nn.Conv2d(in_channels, out_channels, kernel_size=1,stride=1) if in_channels != out_channels else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Define ResNetBlock2\n",
    "class ResNetBlock2(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResNetBlock2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.conv3 is not None:\n",
    "            identity = self.conv3(x)\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Define the entire network\n",
    "class FinalCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FinalCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = ResNetBlock1(in_channels=64, out_channels=64)\n",
    "        self.layer2 = ResNetBlock2(in_channels=64, out_channels=128)\n",
    "        self.layer3 = ResNetBlock1(in_channels=128, out_channels=256)\n",
    "        self.layer4 = ResNetBlock2(in_channels=256, out_channels=128)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((2, 2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(512, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 128)\n",
    "        #self.dropout = nn.Dropout(0.5)\n",
    "        self.fc3 = nn.Linear(128, 128)  # 64 for real and 64 for imaginary\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #x = self.dropout(x)\n",
    "        x = torch.tanh(self.fc3(x))  # Clamping the output to be within [-1, 1]\n",
    "        return x\n",
    "\n",
    "\n",
    "# Function to process image file\n",
    "def process_image_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    images = []\n",
    "    image = []\n",
    "    for line in lines:\n",
    "        row = [int(pixel) for pixel in line.strip().split(',')]\n",
    "        image.append(row)\n",
    "        if len(image) == 64:\n",
    "            images.append(image)\n",
    "            image = []\n",
    "    images = np.array(images, dtype=np.float32)\n",
    "    images = images.reshape(-1, 1, 64, 64)  # -1 to automatically determine the number of images\n",
    "    return images\n",
    "\n",
    "\n",
    "file_path1 = 'Simulator_Data/sample135_matrix.txt'  \n",
    "images = process_image_file(file_path1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Custom dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images):\n",
    "        self.images = torch.tensor(images, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "dataset = ImageDataset(images )\n",
    "test_loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Accuracy calculation function\n",
    "\n",
    "\n",
    "\n",
    "# Load the saved model\n",
    "model_path = 'Simulator_trained/model_28_1039.pth'  # replace with your saved model path\n",
    "model = FinalCNN().to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Run the model on the new test dataset\n",
    "\n",
    "predicted_real = []\n",
    "predicted_imag = []\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        outputs_real = outputs[:, :64]\n",
    "        outputs_imag = outputs[:, 64:]\n",
    "\n",
    "\n",
    "        predicted_real.append(outputs_real.cpu().numpy())\n",
    "        predicted_imag.append(outputs_imag.cpu().numpy())\n",
    "\n",
    "\n",
    "# Convert collected lists to numpy arrays\n",
    "\n",
    "predicted_real = np.concatenate(predicted_real, axis=0)\n",
    "predicted_imag = np.concatenate(predicted_imag, axis=0)\n",
    "\n",
    "# Combine real and imaginary parts to form complex numbers\n",
    "\n",
    "predicted_complex = predicted_real + 1j * predicted_imag\n",
    "\n",
    "# Execution time\n",
    "# End time\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "finland_timezone = pytz.timezone('Europe/Helsinki')\n",
    "current_time =datetime.now(finland_timezone).strftime('%d%m%y')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(f'Generated_result/sample135_complex.txt', 'w') as f:\n",
    "    for i in range(len(predicted_complex)):\n",
    "        line = []\n",
    "        for j in range(64):\n",
    "            real_part = f\"{predicted_complex[i, j].real:.4f}\"\n",
    "            imag_part = predicted_complex[i, j].imag\n",
    "            # If imaginary part is negative, keep the minus sign, else add a plus sign\n",
    "            imag_str = f\"+{imag_part:.4f}\" if imag_part >= 0 else f\"{imag_part:.4f}\"\n",
    "            line.append(f\"{real_part}{imag_str}i\")\n",
    "        f.write(\"\\t\".join(line) + \"\\n\")\n",
    "\n",
    "print(\"Predicted data saved successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5c690-41c1-4f8b-ba81-8e39737d9601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
